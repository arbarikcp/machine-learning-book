{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f9e0354",
   "metadata": {},
   "source": [
    "### Data Leakage\n",
    "- A naive approach to preparing data applies the transform on the entire dataset before evaluating the performance of the model. This results in a problem referred to as **data leakage**,\n",
    "- where knowledge of the hold-out test set leaks into the dataset used to train the model. This can result in an incorrect estimate of model performance when making predictions on new data.\n",
    "- When data from the future is leaked to the past. Any time that a model is given information that it shouldn‚Äôt have access to when it is making predictions in real time in production, there is leakage.  \n",
    "- We get data leakage by applying data preparation techniques to the entire dataset. This is not a direct type of data leakage, where we would train the model on the test dataset. Instead, it is an indirect type of data leakage, where some knowledge about the test dataset, captured in summary statistics is available to the model during training.\n",
    "\n",
    "#### Example 1: Using Future Data (Time Series Leakage)\n",
    "- Suppose you are predicting tomorrow‚Äôs stock price using past data\n",
    "- Your dataset accidentally includes a feature like:\n",
    "\n",
    "| Date  | Closing Price | 7-Day Moving Avg (calculated using future days!) |\n",
    "| ----- | ------------- | ------------------------------------------------ |\n",
    "| Jan 1 | 100           | 105                                              |\n",
    "| Jan 2 | 98            | 103                                              |\n",
    "| ...   |               |                                                  |\n",
    "\n",
    "- If that moving average uses future prices, then your model is seeing information from after the prediction moment.\n",
    "- üëâ In reality, when predicting Jan 1, you cannot know Jan 7 values.\n",
    "üìå Result:\n",
    "    - Training accuracy: 98%\n",
    "    - Real-world accuracy: 50% or random\n",
    "\n",
    "#### Example 2: Target Leakage\n",
    "- Predicting whether a customer will default on a loan.\n",
    "- Suppose our dataset includes a column, `Paid_late_last_month`.    and the label you are predicting is `loan_default`\n",
    "- If this feature is strongly correlated with the output because it happens after the loan approval, then the model is learning something it wouldn‚Äôt know at decision time.\n",
    "- Model learns:\n",
    "\n",
    "- üëâ ‚ÄúIf paid_late_last_month = Yes ‚Üí predict default.‚Äù\n",
    "- But in real deployment this feature won‚Äôt exist at the time of loan approval.\n",
    "- üìå Result: Unrealistically high validation score.\n",
    "\n",
    "#### Example 3: Data Split Leakage\n",
    "- Suppose, You scale or normalize the full dataset before splitting into train and test:\n",
    "- \n",
    "``` scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)   # WRONG\n",
    "    train, test = train_test_split(df_scaled)\n",
    "```\n",
    "- fit_transform used all data statistics, including test set.\n",
    "- So the model indirectly sees test distribution.\n",
    "\n",
    "#### How to Prevent Leakage\n",
    "- ‚úî Split data before preprocessing, scaling, and feature selection\n",
    "- ‚úî For time-series: split chronologically (train ‚Üí past, test ‚Üí future)\n",
    "- ‚úî Avoid using future or outcome-derived features\n",
    "- ‚úî Validate feature logic: ‚ÄúWould I know this before prediction?‚Äù\n",
    "- ‚úî Use pipelines (sklearn.pipeline.Pipeline) to prevent accidental leakage\n",
    "\n",
    "#### Quick Detection Rule\n",
    "- Ask this question:\n",
    "    - Would this information be available at the exact moment the prediction is made?   \n",
    "    - If the answer is No ‚Üí leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee204b17",
   "metadata": {},
   "source": [
    "#### Generate Test dataset using sklearn\n",
    "- sklearn's dataset package has various data generation functions.\n",
    "    - example: make_classification, make_regression, make_circles, make_moons   \n",
    "- Using sklearn's real datasets\n",
    "    - example: load_iris, load_boston, load_diabetes, load_wine\n",
    "- We can use `faker` or `synthetic-data-generator` to generate synthetic data.\n",
    "- Also we can use Numpy/pamdas to generate Dataframes manually using    `np.random.randn`, `np.random.randint` \n",
    "\n",
    "- https://scikit-learn.org/stable/api/sklearn.datasets.html\n",
    "\n",
    "- https://github.com/mwaskom/seaborn-data/tree/master\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91e75ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['make_biclusters',\n",
      " 'make_blobs',\n",
      " 'make_checkerboard',\n",
      " 'make_circles',\n",
      " 'make_classification',\n",
      " 'make_friedman1',\n",
      " 'make_friedman2',\n",
      " 'make_friedman3',\n",
      " 'make_gaussian_quantiles',\n",
      " 'make_hastie_10_2',\n",
      " 'make_low_rank_matrix',\n",
      " 'make_moons',\n",
      " 'make_multilabel_classification',\n",
      " 'make_regression',\n",
      " 'make_s_curve',\n",
      " 'make_sparse_coded_signal',\n",
      " 'make_sparse_spd_matrix',\n",
      " 'make_sparse_uncorrelated',\n",
      " 'make_spd_matrix',\n",
      " 'make_swiss_roll']\n"
     ]
    }
   ],
   "source": [
    "# List all the data generation functions present in sklearn\n",
    "from sklearn import datasets\n",
    "import inspect, pprint\n",
    "\n",
    "\n",
    "# List all callables that start with \"make_\"\n",
    "make_funcs = [name for name in dir(datasets) if name.startswith(\"make_\")]\n",
    "pprint.pprint(make_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f7bcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(\n",
    "        n_samples=1000,      # total number of data points (rows) to generate\n",
    "        n_features=20,      # total number of columns (features) per sample\n",
    "        n_informative=15,   # how many of those 20 features actually influence the class label\n",
    "        n_redundant=5,      # how many features are linear combinations of the informative ones\n",
    "        random_state=7)     # seed for the random number generator ‚Üí reproducible results\n",
    "\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c625fee7",
   "metadata": {},
   "source": [
    "#### Model training with Data Leakage   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "448d6351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# standardize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8056c",
   "metadata": {},
   "source": [
    "#### Model training without Data Leakage   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b761e4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.455\n"
     ]
    }
   ],
   "source": [
    "# Correct approach for normalizing the data after the data is split before the model is evaluated\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# define the scaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(X_train)\n",
    "# scale the training dataset\n",
    "X_train = scaler.transform(X_train)\n",
    "# scale the test dataset\n",
    "X_test = scaler.transform(X_test)\n",
    "# fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0e7c81",
   "metadata": {},
   "source": [
    "- In this case, we can see that the estimate for the model is about 85.455 percent, \n",
    "- which is more accurate than the estimate with data leakage in the previous section that achieved an accuracy of 84.848 percent. \n",
    "- We expect data leakage to result in an incorrect estimate of model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f1c8d",
   "metadata": {},
   "source": [
    "#### Data Preparation With k-fold Cross-Validation\n",
    "- **k-fold cross-validation** involves splitting a dataset into k non-overlapping groups of rows. The model is then trained on all but one group to form a training dataset and then evaluated on the held-out fold\n",
    "- This process is repeated so that each fold is given a chance to be used as the holdout test set. Finally, the average performance across all evaluations is reported. \n",
    "- The k-fold cross-validation procedure generally gives a more reliable estimate of model performance than a train-test split, although it is more computationally expensive given the repeated fitting and evaluation of models.\n",
    "\n",
    "- ##### RepeatedStratifiedKFold is a cross‚Äëvalidation iterator from scikit‚Äëlearn (sklearn.model_selection). \n",
    "- It combines two ideas:\n",
    "    - **StratifiedKFold**: the data are split into K folds while preserving the class‚Äëlabel distribution in each fold (i.e., each fold has roughly the same proportion of each class as the whole dataset). This is important for classification problems with imbalanced classes.\n",
    "    - **RepeatedKFold**: the whole K-fold splitting process is performed multiple times, each time with a different random shuffling of the data. This yields a larger set of train‚Äëtest splits, which can give a more reliable estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77716438",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(\n",
    "        n_splits=10,      # create 10 folds (i.e., 10‚Äëfold CV)\n",
    "        n_repeats=3,      # repeat the 10‚Äëfold split 3 times ‚Üí 30 total train/test splits\n",
    "        random_state=1)   # seed for reproducibility of the random shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94eb9415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 1, Fold 1\n",
      "  Train class distribution ‚Üí 0:14, 1:6\n",
      "  Test  class distribution ‚Üí 0:7, 1:3\n",
      "---\n",
      "Repeat 1, Fold 2\n",
      "  Train class distribution ‚Üí 0:14, 1:6\n",
      "  Test  class distribution ‚Üí 0:7, 1:3\n",
      "---\n",
      "Repeat 1, Fold 3\n",
      "  Train class distribution ‚Üí 0:14, 1:6\n",
      "  Test  class distribution ‚Üí 0:7, 1:3\n",
      "---\n",
      "Repeat 1, Fold 4\n",
      "  Train class distribution ‚Üí 0:14, 1:6\n",
      "  Test  class distribution ‚Üí 0:7, 1:3\n",
      "---\n",
      "Repeat 1, Fold 5\n",
      "  Train class distribution ‚Üí 0:14, 1:6\n",
      "  Test  class distribution ‚Üí 0:7, 1:3\n",
      "---\n",
      "Repeat 1, Fold 6\n",
      "  Train class distribution ‚Üí 0:14, 1:6\n",
      "  Test  class distribution ‚Üí 0:7, 1:3\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1Ô∏è‚É£ Create a tiny binary‚Äëclassification dataset\n",
    "# -------------------------------------------------\n",
    "X, y = make_classification(\n",
    "    n_samples=30,          # only 30 rows ‚Äì easy to inspect\n",
    "    n_features=5,\n",
    "    n_informative=3,\n",
    "    n_redundant=0,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.7, 0.3],    # 70‚ÄØ% class 0, 30‚ÄØ% class 1 (imbalanced)\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2Ô∏è‚É£ Set up repeated stratified K‚Äëfold\n",
    "#    - 3 folds per repeat\n",
    "#    - repeat the whole split 2 times\n",
    "# -------------------------------------------------\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=1)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3Ô∏è‚É£ Iterate over the generated splits\n",
    "# -------------------------------------------------\n",
    "for i, (train_idx, test_idx) in enumerate(cv.split(X, y), start=1):\n",
    "    # Which repeat are we in? (every n_splits folds belong to the same repeat)\n",
    "    repeat_num = (i - 1) // cv.get_n_splits() + 1\n",
    "    fold_num   = (i - 1) % cv.get_n_splits() + 1\n",
    "\n",
    "    # Count how many samples of each class appear in train / test\n",
    "    train_counts = np.bincount(y[train_idx], minlength=2)\n",
    "    test_counts  = np.bincount(y[test_idx],  minlength=2)\n",
    "\n",
    "    print(f\"Repeat {repeat_num}, Fold {fold_num}\")\n",
    "    print(f\"  Train class distribution ‚Üí 0:{train_counts[0]}, 1:{train_counts[1]}\")\n",
    "    print(f\"  Test  class distribution ‚Üí 0:{test_counts[0]}, 1:{test_counts[1]}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45386a9",
   "metadata": {},
   "source": [
    "#### Cross-Validation Evaluation With Naive Data Preparation (with Data Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "789e43e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.300 (3.607)\n"
     ]
    }
   ],
   "source": [
    "# naive data preparation for model evaluation with k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# standardize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model using cross-validation\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores)*100, std(scores)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a64142",
   "metadata": {},
   "source": [
    "#### Cross-Validation Evaluation With Naive correct Data Preparation (without Data Leakage)\n",
    "- Data preparation without data leakage when using cross-validation is slightly more challenging.\n",
    "\n",
    "- we should constrain ourselves to developing the list of preprocessing techniques, estimate them only in the presence of the training data points, and then apply the techniques to future data (including the test set).\n",
    "\n",
    "- We can achieve this by defining a modeling pipeline that defines a sequence of data preparation steps to perform and ending in the model to fit and evaluate.\n",
    "\n",
    "- to correctly evaluating the entire pipeline of data preparation and model together as a single atomic unit. This can be achieved using the `Pipeline` class.\n",
    "\n",
    "- \n",
    "    ```\n",
    "    # define the pipeline\n",
    "    steps = list()\n",
    "    steps.append(('scaler', MinMaxScaler())) \n",
    "    steps.append(('model', LogisticRegression())) \n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    ```\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91b9ffa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.433 (3.471)\n"
     ]
    }
   ],
   "source": [
    "# correct data preparation for model evaluation with k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# define the pipeline\n",
    "steps = list()\n",
    "steps.append(('scaler', MinMaxScaler()))\n",
    "steps.append(('model', LogisticRegression()))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# evaluate the model using cross-validation\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores)*100, std(scores)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
